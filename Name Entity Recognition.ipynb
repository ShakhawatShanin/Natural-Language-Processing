{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Named Entity Recognition(NER)\n- **Named Entity**\n    - ORGANIZATION\n    - PERSON\n    - PRODUCT\n    - MONEY\n    - GPE\n    - ORDINAL\n    - LOCATION\n    - DATE\n    - TIME","metadata":{}},{"cell_type":"code","source":"import nltk\nimport pandas as pd\n# from nltk import word_tokenize,pos_tag","metadata":{"execution":{"iopub.status.busy":"2021-10-24T13:44:51.406413Z","iopub.execute_input":"2021-10-24T13:44:51.406866Z","iopub.status.idle":"2021-10-24T13:44:53.087598Z","shell.execute_reply.started":"2021-10-24T13:44:51.406820Z","shell.execute_reply":"2021-10-24T13:44:53.086489Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"text = \"Apple acquired Zoom in China on Wednesday 6th May 2020.\\\nThis news has made Apple and Google stock jump by 5% on Dow Jones Index in the \\\nUnited States of America\"","metadata":{"execution":{"iopub.status.busy":"2021-10-24T13:44:56.215920Z","iopub.execute_input":"2021-10-24T13:44:56.216432Z","iopub.status.idle":"2021-10-24T13:44:56.220997Z","shell.execute_reply.started":"2021-10-24T13:44:56.216383Z","shell.execute_reply":"2021-10-24T13:44:56.220102Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**NLTK provides a function nltk.ne_chunk() that is already a pre-trained classifier to recognize named entity using POS tag as input**","metadata":{}},{"cell_type":"code","source":"# tokenize to words\nwords = nltk.word_tokenize(text)\nwords","metadata":{"execution":{"iopub.status.busy":"2021-10-24T13:44:59.007455Z","iopub.execute_input":"2021-10-24T13:44:59.008066Z","iopub.status.idle":"2021-10-24T13:44:59.036687Z","shell.execute_reply.started":"2021-10-24T13:44:59.008028Z","shell.execute_reply":"2021-10-24T13:44:59.035579Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Part of speech tagging | Find parts of speech tag for each word using the pos_tag() function\npos_tags = nltk.pos_tag(words)\npos_tags","metadata":{"execution":{"iopub.status.busy":"2021-10-24T13:45:02.687140Z","iopub.execute_input":"2021-10-24T13:45:02.687605Z","iopub.status.idle":"2021-10-24T13:45:02.868382Z","shell.execute_reply.started":"2021-10-24T13:45:02.687566Z","shell.execute_reply":"2021-10-24T13:45:02.867324Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Binary = True | Pass the list that contains tuples of words and POS tags to the ne_chunk() function\nchunks = nltk.ne_chunk(pos_tags, binary=False)     # True give u two outputs either the word is NE or not NE\n                                                   # False show u either NE or not NE and also print label(Person, Organization, GPE) of theses NE\nfor chunk in chunks:\n    print(chunk)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T13:45:07.926308Z","iopub.execute_input":"2021-10-24T13:45:07.927128Z","iopub.status.idle":"2021-10-24T13:45:08.138332Z","shell.execute_reply.started":"2021-10-24T13:45:07.927081Z","shell.execute_reply":"2021-10-24T13:45:08.137136Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## IOB tagging\n- **The IOB format (short for inside, outside, beginning) is a tagging format. These tags are similar to part-of-speech tags but give us information about the location of the word in the chunk**\n    - B-{CHUNK_TYPE} – for the word in the Beginning chunk\n    - I-{CHUNK_TYPE} – for words Inside the chunk\n    - O – Outside any chunk","metadata":{}},{"cell_type":"code","source":"from nltk.chunk import tree2conlltags\niob_tagged = tree2conlltags(chunks)\nfor chunk in iob_tagged:\n    print(chunk)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T13:45:13.071913Z","iopub.execute_input":"2021-10-24T13:45:13.072419Z","iopub.status.idle":"2021-10-24T13:45:13.082742Z","shell.execute_reply.started":"2021-10-24T13:45:13.072375Z","shell.execute_reply":"2021-10-24T13:45:13.081593Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"entities =[]\nlabels =[]\nfor chunk in chunks:\n    if hasattr(chunk,'label'):\n        # print(chunk)\n        entities.append(' '.join(c[0] for c in chunk))\n        labels.append(chunk.label())\n        \nentities_labels = list(set(zip(entities, labels)))\nentities_df = pd.DataFrame(entities_labels)\nentities_df.columns = [\"Entities\", \"Labels\"]\nentities_df","metadata":{"execution":{"iopub.status.busy":"2021-10-24T13:45:21.352578Z","iopub.execute_input":"2021-10-24T13:45:21.353035Z","iopub.status.idle":"2021-10-24T13:45:21.391264Z","shell.execute_reply.started":"2021-10-24T13:45:21.352997Z","shell.execute_reply":"2021-10-24T13:45:21.390158Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Sentence based(whole code together)\nentities = []\nlabels = []\n\nsentence = nltk.sent_tokenize(text)\nfor sent in sentence:\n    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent)), binary=False):\n        if hasattr(chunk,'label'):\n            entities.append(' '.join(c[0] for c in chunk))\n            labels.append(chunk.label())\n            \nentities_labels = list(set(zip(entities,labels)))\n\nentities_df = pd.DataFrame(entities_labels)\nentities_df.columns = [\"Entities\",\"Labels\"]\nentities_df","metadata":{"execution":{"iopub.status.busy":"2021-10-24T13:45:27.529800Z","iopub.execute_input":"2021-10-24T13:45:27.530328Z","iopub.status.idle":"2021-10-24T13:45:27.566808Z","shell.execute_reply.started":"2021-10-24T13:45:27.530284Z","shell.execute_reply":"2021-10-24T13:45:27.565763Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Using Spacy","metadata":{}},{"cell_type":"code","source":"import spacy \nfrom spacy import displacy\nspacy.__version__  # SpaCy 2.x brough significant speed and accuracy improvements","metadata":{"execution":{"iopub.status.busy":"2021-10-24T13:45:44.857219Z","iopub.execute_input":"2021-10-24T13:45:44.857682Z","iopub.status.idle":"2021-10-24T13:45:45.836060Z","shell.execute_reply.started":"2021-10-24T13:45:44.857640Z","shell.execute_reply":"2021-10-24T13:45:45.834718Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# what type a particular NE is\n\nprint(spacy.explain(\"ORG\"))\nprint(spacy.explain(\"PERSON\"))\nprint(spacy.explain(\"PRODUCT\"))\nprint(spacy.explain(\"GPE\"))\nprint(spacy.explain(\"LOC\"))\nprint(spacy.explain(\"DATE\"))\nprint(spacy.explain(\"ORDINAL\"))\nprint(spacy.explain(\"MONEY\"))","metadata":{"execution":{"iopub.status.busy":"2021-10-24T13:52:11.334780Z","iopub.execute_input":"2021-10-24T13:52:11.335428Z","iopub.status.idle":"2021-10-24T13:52:11.349659Z","shell.execute_reply.started":"2021-10-24T13:52:11.335371Z","shell.execute_reply":"2021-10-24T13:52:11.347750Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Download and Load SpaCy model\n\n# 3 types of pre-trained models\nnlp = spacy.load(\"en_core_web_sm\")    # EN:English, CORE:Vocabulary, syntax, entities, WEB:written text (blogs, news, comments), SM:size(12MB)\n#nlp = spacy.load(\"en_core_web_md\")\n#nlp = spacy.load(\"en_core_web_lg\")","metadata":{"execution":{"iopub.status.busy":"2021-10-24T13:53:14.595105Z","iopub.execute_input":"2021-10-24T13:53:14.595691Z","iopub.status.idle":"2021-10-24T13:53:15.847805Z","shell.execute_reply.started":"2021-10-24T13:53:14.595649Z","shell.execute_reply":"2021-10-24T13:53:15.846614Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"doc = nlp(text)\n\nentities = []\nlabels = []\nposition_start = []\nposition_end = []\n\nfor ent in doc.ents:\n    entities.append(ent)\n    labels.append(ent.label_)\n    position_start.append(ent.start_char)\n    position_end.append(ent.end_char)\n    \ndf = pd.DataFrame({'Entities':entities,'Labels':labels,'Position_Start':position_start, 'Position_End':position_end})\ndf","metadata":{"execution":{"iopub.status.busy":"2021-10-24T13:53:19.586011Z","iopub.execute_input":"2021-10-24T13:53:19.586478Z","iopub.status.idle":"2021-10-24T13:53:19.646757Z","shell.execute_reply.started":"2021-10-24T13:53:19.586438Z","shell.execute_reply":"2021-10-24T13:53:19.645579Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"displacy.serve(doc, style=\"ent\")   # display a ui visualization of entities of doc objects","metadata":{"execution":{"iopub.status.busy":"2021-10-24T14:11:12.437420Z","iopub.execute_input":"2021-10-24T14:11:12.437916Z","iopub.status.idle":"2021-10-24T14:42:19.401726Z","shell.execute_reply.started":"2021-10-24T14:11:12.437874Z","shell.execute_reply":"2021-10-24T14:42:19.400357Z"},"trusted":true},"execution_count":20,"outputs":[]}]}