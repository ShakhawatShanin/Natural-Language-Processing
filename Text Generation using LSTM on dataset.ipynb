{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import string\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM\nfrom keras.optimizers import RMSprop\nimport random\nimport sys","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:05:36.112032Z","iopub.execute_input":"2021-10-11T13:05:36.112393Z","iopub.status.idle":"2021-10-11T13:05:41.219253Z","shell.execute_reply.started":"2021-10-11T13:05:36.112315Z","shell.execute_reply":"2021-10-11T13:05:41.218289Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Load Text","metadata":{}},{"cell_type":"code","source":"# Save notepad as UTF-8 \nfilename = \"../input/text-generation/236-0.txt\"\nraw_text = open(filename, 'r', encoding='utf-8').read()  # open file in read mode\nraw_text = raw_text[2096:]   # start at main sentence | character by character\nprint(raw_text[0:500])","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:13:51.422099Z","iopub.execute_input":"2021-10-11T13:13:51.422662Z","iopub.status.idle":"2021-10-11T13:13:51.445439Z","shell.execute_reply.started":"2021-10-11T13:13:51.422598Z","shell.execute_reply":"2021-10-11T13:13:51.444264Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Data Pre-processing","metadata":{"execution":{"iopub.status.busy":"2021-10-06T06:53:50.291837Z","iopub.execute_input":"2021-10-06T06:53:50.292378Z","iopub.status.idle":"2021-10-06T06:53:50.297451Z","shell.execute_reply.started":"2021-10-06T06:53:50.292319Z","shell.execute_reply":"2021-10-06T06:53:50.296342Z"}}},{"cell_type":"code","source":"def clean_text(txt):\n    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n    txt = \"\".join(v for v in txt if not v.isdigit())\n    return txt \n\nraw_text = clean_text(raw_text)\nprint(raw_text[0:500])","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:13:53.799421Z","iopub.execute_input":"2021-10-11T13:13:53.799767Z","iopub.status.idle":"2021-10-11T13:13:53.872698Z","shell.execute_reply.started":"2021-10-11T13:13:53.799735Z","shell.execute_reply":"2021-10-11T13:13:53.871776Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# How many total characters and digit do we have \nchars = sorted(list(set(raw_text)))    # List of every character\nchars   # n_vocab","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:13:55.822938Z","iopub.execute_input":"2021-10-11T13:13:55.823610Z","iopub.status.idle":"2021-10-11T13:13:55.835561Z","shell.execute_reply.started":"2021-10-11T13:13:55.823573Z","shell.execute_reply":"2021-10-11T13:13:55.834755Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# summarize the data\nn_chars = len(raw_text)\nn_vocab = len(chars)\nprint(\"Corpus length: \", n_chars)   # Total Characters in the text\nprint(\"Total Vocab: \", n_vocab)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:13:58.086012Z","iopub.execute_input":"2021-10-11T13:13:58.086334Z","iopub.status.idle":"2021-10-11T13:13:58.091480Z","shell.execute_reply.started":"2021-10-11T13:13:58.086305Z","shell.execute_reply":"2021-10-11T13:13:58.090482Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Each unique character will be assigned an integer value\n# Create a dictionary of characters mapped to integer values\n\nchar_to_int = dict((c, i) for i, c in enumerate(chars))\nchar_to_int\n\n# character    Index\n#     a         2","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:14:01.382344Z","iopub.execute_input":"2021-10-11T13:14:01.382692Z","iopub.status.idle":"2021-10-11T13:14:01.388227Z","shell.execute_reply.started":"2021-10-11T13:14:01.382659Z","shell.execute_reply":"2021-10-11T13:14:01.387629Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"int_to_char = dict((i, c) for i, c in enumerate(chars))\nint_to_char\n\n# Index    Character\n#  2          a","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:14:05.061631Z","iopub.execute_input":"2021-10-11T13:14:05.062169Z","iopub.status.idle":"2021-10-11T13:14:05.068207Z","shell.execute_reply.started":"2021-10-11T13:14:05.062128Z","shell.execute_reply":"2021-10-11T13:14:05.067396Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"seq_length = 60     # Length of each input sequence\nstep = 10           # Instead of moving 1 letter at a time, try skipping a few \nsentences = []      # X values (Sentences)\nnext_chars = []     # Y values. The character that follows the sentence defined as X\nfor i in range(0, n_chars - seq_length, step):     # step=1 means each sentence is offset just by a single letter\n    sentences.append(raw_text[i: i + seq_length])  # Sequence in\n    next_chars.append(raw_text[i + seq_length])    # Sequence out\nn_patterns = len(sentences)    \nprint('Number of sequences:', n_patterns)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:14:09.422883Z","iopub.execute_input":"2021-10-11T13:14:09.423371Z","iopub.status.idle":"2021-10-11T13:14:09.446513Z","shell.execute_reply.started":"2021-10-11T13:14:09.423333Z","shell.execute_reply":"2021-10-11T13:14:09.445598Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(sentences[0])\nprint(\"Output: \", next_chars[0])\n\n# input: I love Cricke\n# output: t","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:14:12.255681Z","iopub.execute_input":"2021-10-11T13:14:12.256031Z","iopub.status.idle":"2021-10-11T13:14:12.261741Z","shell.execute_reply.started":"2021-10-11T13:14:12.256002Z","shell.execute_reply":"2021-10-11T13:14:12.260599Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Vectorization","metadata":{}},{"cell_type":"code","source":"# Rescale the integers to the range 0-to-1 \n# reshape input to be [samples, time steps, features]\n# time steps = sequence length\n# features = numbers of characters in our vocab (n_vocab)\n\n# Vectorize all sentences: there are n_patterns sentences\n# For each sentence we have n_vocab characters available for seq_length\n# Vectorization returns a vector for all sentences indicating the presence or absence of a character. \n\nx = np.zeros((len(sentences), seq_length, n_vocab), dtype=np.bool)\ny = np.zeros((len(sentences), n_vocab), dtype=np.bool)\nfor i, sentence in enumerate(sentences):\n    for t, char in enumerate(sentence):\n        x[i, t, char_to_int[char]] = 1\n    y[i, char_to_int[next_chars[i]]] = 1\n    \nprint(x.shape)\nprint(y.shape)\n\nprint(y[0:3])","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:14:15.672448Z","iopub.execute_input":"2021-10-11T13:14:15.672819Z","iopub.status.idle":"2021-10-11T13:14:16.274035Z","shell.execute_reply.started":"2021-10-11T13:14:15.672783Z","shell.execute_reply":"2021-10-11T13:14:16.272949Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Build LSTM model","metadata":{}},{"cell_type":"code","source":"mymodel = Sequential()\nmymodel.add(LSTM(128, input_shape=(seq_length, n_vocab)))\nmymodel.add(Dense(n_vocab, activation='softmax'))\n\noptimizer = RMSprop(lr = 0.01)\nmymodel.compile(loss = 'categorical_crossentropy', optimizer=optimizer)\nmymodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:14:19.375281Z","iopub.execute_input":"2021-10-11T13:14:19.375607Z","iopub.status.idle":"2021-10-11T13:14:19.757719Z","shell.execute_reply.started":"2021-10-11T13:14:19.375576Z","shell.execute_reply":"2021-10-11T13:14:19.756766Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Define the Checkpoint","metadata":{"execution":{"iopub.status.busy":"2021-10-10T06:24:08.374995Z","iopub.execute_input":"2021-10-10T06:24:08.375412Z","iopub.status.idle":"2021-10-10T06:24:08.380366Z","shell.execute_reply.started":"2021-10-10T06:24:08.375379Z","shell.execute_reply":"2021-10-10T06:24:08.379225Z"}}},{"cell_type":"code","source":"\nfrom keras.callbacks import ModelCheckpoint\n\nfilepath=\"saved_weights/saved_weights-{epoch:02d}-{loss:.4f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n\ncallbacks_list = [checkpoint]","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:14:22.279055Z","iopub.execute_input":"2021-10-11T13:14:22.279393Z","iopub.status.idle":"2021-10-11T13:14:22.283846Z","shell.execute_reply.started":"2021-10-11T13:14:22.279363Z","shell.execute_reply":"2021-10-11T13:14:22.283151Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Fit the model\nmymodel.fit(x, y, batch_size=128, epochs=5, callbacks=callbacks_list)\nmymodel.save('my_saved_weights_jungle_book_50epochs.h5')","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:14:24.688343Z","iopub.execute_input":"2021-10-11T13:14:24.688851Z","iopub.status.idle":"2021-10-11T13:16:20.850026Z","shell.execute_reply.started":"2021-10-11T13:14:24.688802Z","shell.execute_reply":"2021-10-11T13:16:20.849358Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Generate characters function ","metadata":{}},{"cell_type":"code","source":"# We must provide a sequence of seq_lenth as input to start the generation process\n# The prediction results is probabilities for each of the 32 characters at a specific & pick the one with max probability and print it out.\n\ndef sample(preds):\n    preds = np.asarray(preds).astype('float64')\n    preds = np.log(preds)\n    exp_preds = np.exp(preds) #exp of log (x), isn't this same as x??\n    preds = exp_preds / np.sum(exp_preds)\n    probas = np.random.multinomial(1, preds, 1) \n    return np.argmax(probas)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:16:26.970470Z","iopub.execute_input":"2021-10-11T13:16:26.970809Z","iopub.status.idle":"2021-10-11T13:16:26.976556Z","shell.execute_reply.started":"2021-10-11T13:16:26.970778Z","shell.execute_reply":"2021-10-11T13:16:26.975411Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Pick a random sentence from the text as seed(between n_chars)\nstart_index = random.randint(0, n_chars - seq_length - 1)\nprint(start_index)\n\n# Our seed for prediction | Initiate generated text and keep adding new predictions and print them out\ngenerated = ''\nsentence = raw_text[start_index: start_index + seq_length]\ngenerated += sentence\nprint(generated)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:16:30.007207Z","iopub.execute_input":"2021-10-11T13:16:30.007534Z","iopub.status.idle":"2021-10-11T13:16:30.013148Z","shell.execute_reply.started":"2021-10-11T13:16:30.007505Z","shell.execute_reply":"2021-10-11T13:16:30.012112Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print('Seed for our text prediction: \"' + sentence + '\"')\n\n\nfor i in range(100):     # Number of characters including spaces\n    x_pred = np.zeros((1, seq_length, n_vocab))\n    for t, char in enumerate(sentence):\n        x_pred[0, t, char_to_int[char]] = 1.\n\n    preds = mymodel.predict(x_pred, verbose=0)[0]\n    next_index = sample(preds)\n    next_char = int_to_char[next_index]\n\n    generated += next_char\n    sentence = sentence[1:] + next_char\n\n    sys.stdout.write(next_char)\n    sys.stdout.flush()\nprint()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T13:16:32.441841Z","iopub.execute_input":"2021-10-11T13:16:32.442182Z","iopub.status.idle":"2021-10-11T13:16:36.796220Z","shell.execute_reply.started":"2021-10-11T13:16:32.442148Z","shell.execute_reply":"2021-10-11T13:16:36.795545Z"},"trusted":true},"execution_count":17,"outputs":[]}]}