{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Sentence -> word -> creat pair sequence of two words by array list -> given word(input) for prediction and prdict output(corresponding next word) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import array\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Embedding","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:56:07.159512Z","iopub.execute_input":"2021-09-26T14:56:07.160107Z","iopub.status.idle":"2021-09-26T14:56:07.165865Z","shell.execute_reply.started":"2021-09-26T14:56:07.160055Z","shell.execute_reply":"2021-09-26T14:56:07.164874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Source Text ","metadata":{}},{"cell_type":"code","source":"data = \"\"\"Shakib Al Hasan is a Bangladeshi international cricketer. He is considered to be one of the greatest all-rounders of all time.\\n\nHe was ranked as one of the world's most famous athletes by ESPN World Fame 100 in 2019. His aggressive left-handed batting style in the middle order,\\n\ncontrolled slow left-arm orthodox bowling has made him a consistent player for Bangladesh. Shakib is the highest wicket taker for Bangladesh in all international formats.\\n\nIn August 2021, he became the first cricketer to have the double of 100 wickets and 1,000 runs in T20Is history. He is now the only player in the world,\\n\nwho have the double of 100 wickets and 1000 runs feat, in all three formats of men's cricket.\"\"\"\ndata","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:56:09.551706Z","iopub.execute_input":"2021-09-26T14:56:09.552091Z","iopub.status.idle":"2021-09-26T14:56:09.559178Z","shell.execute_reply.started":"2021-09-26T14:56:09.552055Z","shell.execute_reply":"2021-09-26T14:56:09.557837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encoded text","metadata":{}},{"cell_type":"code","source":"# Sentence -> word -> encode words\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts([data])\nencoded_data = tokenizer.texts_to_sequences([data])[0]\nencoded_data","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:56:11.699812Z","iopub.execute_input":"2021-09-26T14:56:11.700196Z","iopub.status.idle":"2021-09-26T14:56:11.710298Z","shell.execute_reply.started":"2021-09-26T14:56:11.700159Z","shell.execute_reply":"2021-09-26T14:56:11.708974Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vocabulary size\nvocab_size = len(tokenizer.word_index) + 1   # 0 is reserved for padding so that's why added 1 | don't count start from 0 \nvocab_size","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:56:16.012241Z","iopub.execute_input":"2021-09-26T14:56:16.012786Z","iopub.status.idle":"2021-09-26T14:56:16.019576Z","shell.execute_reply.started":"2021-09-26T14:56:16.012733Z","shell.execute_reply":"2021-09-26T14:56:16.018366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Sequences","metadata":{}},{"cell_type":"code","source":"Sequences = list()\nfor i in range(1, len(encoded_data)):   # goes upto encoded data(79)\n    sequence = encoded_data[i-1:i+1]\n    Sequences.append(sequence)    # store in list\nprint('Total Sequences: %d' % len(Sequences))\nprint(Sequences)   # [to, be] -> [one, ]| we have total 124 input-output pairs","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:56:17.618738Z","iopub.execute_input":"2021-09-26T14:56:17.619118Z","iopub.status.idle":"2021-09-26T14:56:17.626134Z","shell.execute_reply.started":"2021-09-26T14:56:17.619082Z","shell.execute_reply":"2021-09-26T14:56:17.624897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split train and test","metadata":{}},{"cell_type":"code","source":"# [input, output] | input & output are the columns\nSequences = array(Sequences)\nX, y = Sequences[:,0], Sequences[:,1]\nprint(X[:5])\nprint(y[:5])   ","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:56:21.482573Z","iopub.execute_input":"2021-09-26T14:56:21.482941Z","iopub.status.idle":"2021-09-26T14:56:21.492355Z","shell.execute_reply.started":"2021-09-26T14:56:21.482905Z","shell.execute_reply":"2021-09-26T14:56:21.491298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One Hot Encoding for y column\ny = to_categorical(y, num_classes = vocab_size)\ny[:5]   # after one hot encoding for 5 values","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:56:23.90384Z","iopub.execute_input":"2021-09-26T14:56:23.90424Z","iopub.status.idle":"2021-09-26T14:56:23.9171Z","shell.execute_reply.started":"2021-09-26T14:56:23.904201Z","shell.execute_reply":"2021-09-26T14:56:23.916106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LSTM model","metadata":{}},{"cell_type":"code","source":"mymodel = Sequential()\nmymodel.add(Embedding(vocab_size, 10, input_length = 1))\nmymodel.add(LSTM(30))\nmymodel.add(Dense(vocab_size, activation = 'softmax'))\nprint(mymodel.summary())","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:05:44.339657Z","iopub.execute_input":"2021-09-26T15:05:44.340083Z","iopub.status.idle":"2021-09-26T15:05:44.767928Z","shell.execute_reply.started":"2021-09-26T15:05:44.340047Z","shell.execute_reply":"2021-09-26T15:05:44.766866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mymodel.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:06:45.537313Z","iopub.execute_input":"2021-09-26T15:06:45.53804Z","iopub.status.idle":"2021-09-26T15:06:45.567374Z","shell.execute_reply.started":"2021-09-26T15:06:45.537988Z","shell.execute_reply":"2021-09-26T15:06:45.566441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mymodel.fit(X, y, epochs = 30)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:06:47.200866Z","iopub.execute_input":"2021-09-26T15:06:47.201547Z","iopub.status.idle":"2021-09-26T15:06:49.993782Z","shell.execute_reply.started":"2021-09-26T15:06:47.20151Z","shell.execute_reply":"2021-09-26T15:06:49.992456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_seq(mymodel, tokenizer, enter_text, n_pred):\n    in_text, result = enter_text, enter_text   # both in_text & result variable store given text\n    \n    for _ in range(n_pred):    # how many times for loops run\n        \n        # encode the text as integer\n        encoded = tokenizer.texts_to_sequences([in_text])[0]\n        encoded = array(encoded)\n        \n        # predict a word in the vocabulary\n        yHat = mymodel.predict_classes(encoded)\n        \n        # \n        out_word = ''\n        for word, index in tokenizer.word_index.items():\n            if index == yHat:\n                out_word = word\n                break\n        in_text, result = out_word, result + ' ' + out_word\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:18:32.580375Z","iopub.execute_input":"2021-09-26T15:18:32.580786Z","iopub.status.idle":"2021-09-26T15:18:32.589281Z","shell.execute_reply.started":"2021-09-26T15:18:32.580752Z","shell.execute_reply":"2021-09-26T15:18:32.588228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict output\nprint(generate_seq(mymodel, tokenizer, 'the', 1))    # also print input word | next n predicted word","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:18:34.030463Z","iopub.execute_input":"2021-09-26T15:18:34.030848Z","iopub.status.idle":"2021-09-26T15:18:34.086523Z","shell.execute_reply.started":"2021-09-26T15:18:34.030812Z","shell.execute_reply":"2021-09-26T15:18:34.085555Z"},"trusted":true},"execution_count":null,"outputs":[]}]}